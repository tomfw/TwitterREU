{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from itertools import chain\n",
    "import math\n",
    "import twittergraph as tg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This doesn't do anything yet\n",
    "# Kindly ignore it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 tweets\nRTs: 5 \n"
     ]
    }
   ],
   "source": [
    "graph = tg.LoadTwitterGraph('/Volumes/pond/Temp/twitter/', 0, n_tweets=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-03-15 04:26:31\n2014-06-13 22:05:22\n"
     ]
    }
   ],
   "source": [
    "print np.min(tg.timeList)\n",
    "print np.max(tg.timeList)\n",
    "split = datetime.datetime(2014, 5, 15) #train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jacDict = {}\n",
    "adamDict = {}\n",
    "nbrDict = {}\n",
    "attDict = {}\n",
    "spDict = {}\n",
    "for node in G_train.nodes():\n",
    "    jacDict[node] = {}\n",
    "    adamDict[node] = {}\n",
    "    nbrDict[node] = {}\n",
    "    attDict[node] = {}\n",
    "    spDict[node] = {}\n",
    "    \n",
    "def get_sp(u, v):\n",
    "    (u,v) = sorted((u,v))\n",
    "    ed = None\n",
    "    if G_train.has_edge(u,v):\n",
    "        ed = G_train.edge[u][v]\n",
    "        G_train.remove_edge(u,v)\n",
    "    if v not in spDict[u]:\n",
    "        try:\n",
    "            spDict[u][v] = nx.shortest_path_length(G_train, u, v)\n",
    "        except:\n",
    "            spDict[u][v] = 1000000\n",
    "    \n",
    "    if ed:\n",
    "        G_train.add_edge(u, v, ed)\n",
    "    return spDict[u][v]\n",
    "            \n",
    "    \n",
    "def get_jac(u, v):\n",
    "    (u,v) = sorted((u,v))\n",
    "    if v not in jacDict[u]:\n",
    "        j = nx.jaccard_coefficient(G_train, [(u, v)])\n",
    "        for x,y,p in j:\n",
    "            jacDict[u][v] = p\n",
    "    return jacDict[u][v]\n",
    "\n",
    "\n",
    "def get_adam(u, v):\n",
    "    (u,v) = sorted((u,v))\n",
    "    if v not in adamDict[u]:\n",
    "        j = nx.adamic_adar_index(G_train, [(u, v)])\n",
    "        try:\n",
    "            for x,y,p in j:\n",
    "                adamDict[u][v] = p\n",
    "        except:\n",
    "            adamDict[u][v] = 0\n",
    "    return adamDict[u][v]\n",
    "\n",
    "\n",
    "def get_adam2(u,v):\n",
    "    (u,v) = sorted((u,v))\n",
    "    score = 0\n",
    "    if v not in adamDict[u]:\n",
    "        for nbr in nx.common_neighbors(G_train, u, v):\n",
    "            deg = nx.degree(G_train, nbr)\n",
    "            if deg >= 2:\n",
    "                score += 1/math.log(deg)\n",
    "        adamDict[u][v] = score\n",
    "    return adamDict[u][v]\n",
    "\n",
    "\n",
    "def get_att(u,v):\n",
    "    (u,v) = sorted((u,v))\n",
    "    if v not in attDict[u]:\n",
    "        j = nx.preferential_attachment(G_train, [(u, v)])\n",
    "        for x,y,p in j:\n",
    "            attDict[u][v] = p\n",
    "    return attDict[u][v]\n",
    "\n",
    "\n",
    "def get_nbrs(u, v):\n",
    "    (u,v) = sorted((u,v))\n",
    "    if v not in nbrDict[u]:\n",
    "        nbrs = 0\n",
    "        for nbr in nx.common_neighbors(G_train, u, v): nbrs += 1\n",
    "        nbrDict[u][v] = nbrs\n",
    "    return nbrDict[u][v]\n",
    "      \n",
    "        \n",
    "def all_pairs(graph):\n",
    "    return chain(graph.edges(), nx.non_edges(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for u,v in all_pairs(G_train):\n",
    "    print get_sp(u,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "2000000\n"
     ]
    }
   ],
   "source": [
    "progress = 0\n",
    "\n",
    "for n1, n2 in all_pairs(G_train):\n",
    "    progress += 1\n",
    "    if progress % 1000000 == 0: print progress\n",
    "    get_nbrs(n1, n2)\n",
    "    get_jac(n1, n2)\n",
    "    get_adam2(n1, n2)\n",
    "    get_att(n1, n2)\n",
    "    get_sp(n1, n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800626 pairs in training set, 29830 edges\n"
     ]
    }
   ],
   "source": [
    "u = []\n",
    "v = []\n",
    "has_links = []\n",
    "jac_co = []\n",
    "adam = []\n",
    "att = []\n",
    "nbrs = []\n",
    "spl = []\n",
    "count = 0\n",
    "for n1, n2 in all_pairs(G_train):\n",
    "    count += 1\n",
    "    u.append(n1)\n",
    "    v.append(n2)\n",
    "    has_links.append(G_train.has_edge(n1,n2))\n",
    "    jac_co.append(get_jac(n1,n2))\n",
    "    adam.append(get_adam2(n1, n2))\n",
    "    att.append(get_att(n1, n2))\n",
    "    nbrs.append(get_nbrs(n1, n2))\n",
    "    spl.append(get_sp(n1, n2))\n",
    "                \n",
    "df_train = pd.DataFrame()\n",
    "df_train['u'] = u\n",
    "df_train['v'] = v\n",
    "df_train['link'] = has_links\n",
    "df_train['jac'] = jac_co\n",
    "df_train['adam'] = adam\n",
    "df_train['nbrs'] = nbrs\n",
    "df_train['att'] = att\n",
    "df_train['spl'] = spl\n",
    "print(\"%d pairs in training set, %d edges\" % (count, np.count_nonzero(has_links)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2770796 pairs in test set, 11205 true edges\n"
     ]
    }
   ],
   "source": [
    "u = []\n",
    "v = []\n",
    "has_links = []\n",
    "jac_co = []\n",
    "adam = []\n",
    "att = []\n",
    "nbrs = []\n",
    "spl = []\n",
    "count = 0\n",
    "\n",
    "for n1, n2 in nx.non_edges(G_train):\n",
    "    u.append(n1)\n",
    "    v.append(n2)\n",
    "    has_links.append(G.has_edge(n1,n2))\n",
    "    jac_co.append(get_jac(n1,n2))\n",
    "    adam.append(get_adam2(n1, n2))\n",
    "    att.append(get_att(n1, n2))\n",
    "    nbrs.append(get_nbrs(n1, n2))\n",
    "    spl.append(get_sp(n1, n2))\n",
    "    count += 1\n",
    "\n",
    "df_test = pd.DataFrame()\n",
    "df_test['u'] = u\n",
    "df_test['v'] = v\n",
    "df_test['link'] = has_links\n",
    "df_test['jac'] = jac_co\n",
    "df_test['adam'] = adam\n",
    "df_test['att'] = att\n",
    "df_test['nbrs'] = nbrs\n",
    "df_test['spl'] = spl\n",
    "print(\"%d pairs in test set, %d true edges\" % (count, np.count_nonzero(has_links)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomfw/Library/Python/2.7/lib/python/site-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000, max_depth=None,\n",
    "    min_samples_split=2, random_state=0, )\n",
    "#rf = SVC(C=.00001, gamma=100, probability=True)\n",
    "fields = ['att']\n",
    "x_train = df_train.loc[:, fields]\n",
    "y_train = np.reshape(df_train.link, (-1, 1))\n",
    "\n",
    "x_test = df_test.loc[:, fields]\n",
    "classifier = rf.fit(x_train, y_train)\n",
    "pred = classifier.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roc_auc_score(np.reshape(df_test.link, (-1, 1)), pred[:,1])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}