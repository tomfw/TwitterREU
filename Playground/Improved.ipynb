{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import calendar\n",
    "import codecs\n",
    "import datetime\n",
    "import json\n",
    "import sys\n",
    "import gzip\n",
    "import string\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import csv\n",
    "import networkx as nx\n",
    "from demjson import decode\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "globalTweetCounter = 0\n",
    "\n",
    "timeFormat = \"%Y-%m-%dT%H:%M:%S.%fZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41633\n"
     ]
    }
   ],
   "source": [
    "countries=['Kenya-community-relevant-restricted.json']\n",
    "\n",
    "for m in range(len(countries)):\n",
    "    file_string=countries[m]\n",
    "    mypath='/Volumes/pond/Temp/twitter/'+file_string\n",
    "    G=nx.Graph()\n",
    "    tweetList = []\n",
    "    timeList = []\n",
    "    userList = []\n",
    "    \n",
    "    with open(mypath) as f1:\n",
    "        for line in f1:\n",
    "           if random.random() < .07: # < 1 if you want less data\n",
    "                tweetObj = json.loads(line)\n",
    "                currentTime = datetime.datetime.strptime(tweetObj['postedTime'], timeFormat)\n",
    "                id2=int(re.findall('^.*:([0-9]+)$',str(tweetObj['actor']['id']))[0])\n",
    "                G.add_node(id2, parent=True, child=False)\n",
    "                for ui in tweetObj['twitter_entities']['user_mentions']:\n",
    "                    id1=ui['id']\n",
    "                    G.add_node(id1, child=True)\n",
    "                    G.add_edge(id1,id2, posted=currentTime, message=tweetObj['body'])\n",
    "                    #print id1, id2\n",
    "                try:\n",
    "                    if (not tweetObj['body'].lower().startswith(\"rt\")):\n",
    "                        # Increment tweet count\n",
    "                        globalTweetCounter += 1\n",
    "                        tweetList.append(tweetObj['body'].lower())\n",
    "                        timeList.append(currentTime)\n",
    "                        userList.append(tweetObj['actor']['id'])\n",
    "                        #print globalTweetCounter, tweetObj['body'].lower()\n",
    "                except:\n",
    "                    pass\n",
    "print globalTweetCounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-01-08 01:06:03\n",
      "2013-04-02 23:31:23\n"
     ]
    }
   ],
   "source": [
    "print np.min(timeList)\n",
    "print np.max(timeList)\n",
    "split = datetime.datetime(2013, 3, 1) #train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72219 28539 41633\n"
     ]
    }
   ],
   "source": [
    "print G.number_of_edges(), G.number_of_nodes(), len(timeList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for node in G.nodes():\n",
    "    nTrain = 0\n",
    "    nTest = 0\n",
    "    for nbr in G.neighbors(node):\n",
    "        if G.edge[node][nbr]['posted'] < split:\n",
    "            nTrain += 1\n",
    "        else:\n",
    "            nTest += 1\n",
    "    if nTrain < 3 or nTest < 3:\n",
    "        G.remove_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G_train = G.copy()\n",
    "\n",
    "for u,v in G_train.edges():\n",
    "    if G_train[u][v]['posted'] > split:\n",
    "        G_train.remove_edge(u,v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full graph: 18286 edges 2057 nodes\n",
      "Training graph: 8763 edges 2057 nodes\n"
     ]
    }
   ],
   "source": [
    "print(\"Full graph: %d edges %d nodes\" % (G.number_of_edges(), G.number_of_nodes()))\n",
    "print(\"Training graph: %d edges %d nodes\" % (G_train.number_of_edges(), G_train.number_of_nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jacDict = {}\n",
    "adamDict = {}\n",
    "nbrDict = {}\n",
    "attDict = {}\n",
    "\n",
    "for node in G_train.nodes():\n",
    "    jacDict[node] = {}\n",
    "    adamDict[node] = {}\n",
    "    nbrDict[node] = {}\n",
    "    attDict[node] = {}\n",
    "\n",
    "def get_jac(u, v):\n",
    "    (u,v) = sorted((u,v))\n",
    "    if v not in jacDict[u]:\n",
    "        j = nx.jaccard_coefficient(G_train, [(n1, n2)])\n",
    "        for x,y,p in j:\n",
    "            jacDict[u][v] = p\n",
    "    return jacDict[u][v]\n",
    "\n",
    "def get_adam(u, v):\n",
    "    (u,v) = sorted((u,v))\n",
    "    if v not in adamDict[u]:\n",
    "        j = nx.adamic_adar_index(G_train, [(n1, n2)])\n",
    "        try:\n",
    "            for x,y,p in j:\n",
    "                adamDict[u][v] = p\n",
    "        except:\n",
    "            adamDict[u][v] = 0\n",
    "    return adamDict[u][v]\n",
    "\n",
    "def get_att(u,v):\n",
    "    (u,v) = sorted((u,v))\n",
    "    if v not in attDict[u]:\n",
    "        j = nx.preferential_attachment(G_train, [(n1, n2)])\n",
    "        for x,y,p in j:\n",
    "            attDict[u][v] = p\n",
    "    return attDict[u][v]\n",
    "\n",
    "def get_nbrs(u, v):\n",
    "    (u,v) = sorted((u,v))\n",
    "    if v not in nbrDict[u]:\n",
    "        nbrs = 0\n",
    "        for nbr in nx.common_neighbors(G_train, u, v): nbrs += 1\n",
    "        nbrDict[u][v] = nbrs\n",
    "    return nbrDict[u][v]\n",
    "        \n",
    "def all_pairs(graph):\n",
    "    return chain(graph.edges(), nx.non_edges(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "2000000\n"
     ]
    }
   ],
   "source": [
    "progress = 0\n",
    "\n",
    "for n1, n2 in all_pairs(G_train):\n",
    "    progress += 1\n",
    "    if progress % 1000000 == 0: print progress\n",
    "    get_nbrs(n1, n2)\n",
    "    get_jac(n1, n2)\n",
    "    get_adam(n1, n2)\n",
    "    get_att(n1, n2)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2114840 pairs in training set, 8763 edges\n"
     ]
    }
   ],
   "source": [
    "u = []\n",
    "v = []\n",
    "has_links = []\n",
    "jac_co = []\n",
    "adam = []\n",
    "att = []\n",
    "nbrs = []\n",
    "count = 0\n",
    "for n1, n2 in all_pairs(G_train):\n",
    "    count += 1\n",
    "    u.append(n1)\n",
    "    v.append(n2)\n",
    "    has_links.append(G_train.has_edge(n1,n2))\n",
    "    jac_co.append(get_jac(n1,n2))\n",
    "    adam.append(get_adam(n1, n2))\n",
    "    att.append(get_att(n1, n2))\n",
    "    nbrs.append(get_nbrs(n1, n2))\n",
    "                \n",
    "df_train = pd.DataFrame()\n",
    "df_train['u'] = u\n",
    "df_train['v'] = v\n",
    "df_train['link'] = has_links\n",
    "df_train['jac'] = jac_co\n",
    "df_train['adam'] = adam\n",
    "df_train['nbrs'] = nbrs\n",
    "df_train['att'] = att\n",
    "print(\"%d pairs in training set, %d edges\" % (count, np.count_nonzero(has_links)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2106077 pairs in test set, 9271 true edges\n"
     ]
    }
   ],
   "source": [
    "u = []\n",
    "v = []\n",
    "has_links = []\n",
    "jac_co = []\n",
    "adam = []\n",
    "att = []\n",
    "nbrs = []\n",
    "count = 0\n",
    "\n",
    "for n1, n2 in nx.non_edges(G_train):\n",
    "    u.append(n1)\n",
    "    v.append(n2)\n",
    "    has_links.append(G.has_edge(n1,n2))\n",
    "    jac_co.append(get_jac(n1,n2))\n",
    "    adam.append(get_adam(n1, n2))\n",
    "    att.append(get_att(n1, n2))\n",
    "    nbrs.append(get_nbrs(n1, n2))\n",
    "    count += 1\n",
    "\n",
    "df_test = pd.DataFrame()\n",
    "df_test['u'] = u\n",
    "df_test['v'] = v\n",
    "df_test['link'] = has_links\n",
    "df_test['jac'] = jac_co\n",
    "df_test['adam'] = adam\n",
    "df_test['att'] = att\n",
    "df_test['nbrs'] = nbrs\n",
    "print(\"%d pairs in test set, %d true edges\" % (count, np.count_nonzero(has_links)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomfw/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=10, max_depth=None,\n",
    "    min_samples_split=2, random_state=0)\n",
    "#rf = SVC(C=.001, gamma=1, probability=True)\n",
    "fields = ['att']\n",
    "x_train = df_train.loc[:, fields]\n",
    "y_train = np.reshape(df_train.link, (-1, 1))\n",
    "\n",
    "x_test = df_test.loc[:, fields]\n",
    "classifier = rf.fit(x_train, y_train)\n",
    "pred = classifier.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78073559874141929"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(np.reshape(df_test.link, (-1, 1)), pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
