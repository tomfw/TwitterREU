{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import calendar\n",
    "import codecs\n",
    "import datetime\n",
    "import json\n",
    "import sys\n",
    "import gzip\n",
    "import string\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import csv\n",
    "import networkx as nx\n",
    "from demjson import decode\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from itertools import chain\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "globalTweetCounter = 0\n",
    "\n",
    "timeFormat = \"%Y-%m-%dT%H:%M:%S.%fZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90502\n"
     ]
    }
   ],
   "source": [
    "countries=['SAfrica-community-relevant-restricted.json']\n",
    "\n",
    "for m in range(len(countries)):\n",
    "    file_string=countries[m]\n",
    "    mypath='/Users/tomfw/Downloads/DataShared/'+file_string\n",
    "    G=nx.Graph()\n",
    "    tweetList = []\n",
    "    timeList = []\n",
    "    userList = []\n",
    "    \n",
    "    with open(mypath) as f1:\n",
    "        for line in f1:\n",
    "           if random.random() < 2: # < 1 if you want less data\n",
    "                tweetObj = json.loads(line)\n",
    "                currentTime = datetime.datetime.strptime(tweetObj['postedTime'], timeFormat)\n",
    "                id2=int(re.findall('^.*:([0-9]+)$',str(tweetObj['actor']['id']))[0])\n",
    "                G.add_node(id2, parent=True, child=False)\n",
    "                for ui in tweetObj['twitter_entities']['user_mentions']:\n",
    "                    id1=ui['id']\n",
    "                    G.add_node(id1, child=True)\n",
    "                    G.add_edge(id1,id2, posted=currentTime, message=tweetObj['body'])\n",
    "                    #print id1, id2\n",
    "                try:\n",
    "                    if (not tweetObj['body'].lower().startswith(\"rt\")):\n",
    "                        # Increment tweet count\n",
    "                        globalTweetCounter += 1\n",
    "                        tweetList.append(tweetObj['body'].lower())\n",
    "                        timeList.append(currentTime)\n",
    "                        userList.append(tweetObj['actor']['id'])\n",
    "                        #print globalTweetCounter, tweetObj['body'].lower()\n",
    "                except:\n",
    "                    pass\n",
    "print globalTweetCounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-03-15 04:26:31\n",
      "2014-06-13 22:05:22\n"
     ]
    }
   ],
   "source": [
    "print np.min(timeList)\n",
    "print np.max(timeList)\n",
    "split = datetime.datetime(2014, 5, 15) #train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173629 26669 90502\n"
     ]
    }
   ],
   "source": [
    "print G.number_of_edges(), G.number_of_nodes(), len(timeList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for node in G.nodes():\n",
    "    nTrain = 0\n",
    "    nTest = 0\n",
    "    for nbr in G.neighbors(node):\n",
    "        if G.edge[node][nbr]['posted'] < split:\n",
    "            nTrain += 1\n",
    "        else:\n",
    "            nTest += 1\n",
    "    if nTrain < 3 or nTest < 3:\n",
    "        G.remove_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_train = G.copy()\n",
    "\n",
    "for u,v in G_train.edges():\n",
    "    if G_train[u][v]['posted'] > split:\n",
    "        G_train.remove_edge(u,v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full graph: 41215 edges 2367 nodes\n",
      "Training graph: 29830 edges 2367 nodes\n"
     ]
    }
   ],
   "source": [
    "print(\"Full graph: %d edges %d nodes\" % (G.number_of_edges(), G.number_of_nodes()))\n",
    "print(\"Training graph: %d edges %d nodes\" % (G_train.number_of_edges(), G_train.number_of_nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacDict = {}\n",
    "adamDict = {}\n",
    "nbrDict = {}\n",
    "attDict = {}\n",
    "spDict = {}\n",
    "for node in G_train.nodes():\n",
    "    jacDict[node] = {}\n",
    "    adamDict[node] = {}\n",
    "    nbrDict[node] = {}\n",
    "    attDict[node] = {}\n",
    "    spDict[node] = {}\n",
    "    \n",
    "def get_sp(u, v):\n",
    "    (u,v) = sorted((u,v))\n",
    "    ed = None\n",
    "    if G_train.has_edge(u,v):\n",
    "        ed = G_train.edge[u][v]\n",
    "        G_train.remove_edge(u,v)\n",
    "    if v not in spDict[u]:\n",
    "        try:\n",
    "            spDict[u][v] = nx.shortest_path_length(G_train, u, v)\n",
    "        except:\n",
    "            spDict[u][v] = 1000000\n",
    "    \n",
    "    if ed:\n",
    "        G_train.add_edge(u, v, ed)\n",
    "    return spDict[u][v]\n",
    "            \n",
    "    \n",
    "def get_jac(u, v):\n",
    "    (u,v) = sorted((u,v))\n",
    "    if v not in jacDict[u]:\n",
    "        j = nx.jaccard_coefficient(G_train, [(u, v)])\n",
    "        for x,y,p in j:\n",
    "            jacDict[u][v] = p\n",
    "    return jacDict[u][v]\n",
    "\n",
    "def get_adam(u, v):\n",
    "    (u,v) = sorted((u,v))\n",
    "    if v not in adamDict[u]:\n",
    "        j = nx.adamic_adar_index(G_train, [(u, v)])\n",
    "        try:\n",
    "            for x,y,p in j:\n",
    "                adamDict[u][v] = p\n",
    "        except:\n",
    "            adamDict[u][v] = 0\n",
    "    return adamDict[u][v]\n",
    "\n",
    "def get_adam2(u,v):\n",
    "    (u,v) = sorted((u,v))\n",
    "    score = 0\n",
    "    if v not in adamDict[u]:\n",
    "        for nbr in nx.common_neighbors(G_train, u, v):\n",
    "            deg = nx.degree(G_train, nbr)\n",
    "            if deg >= 2:\n",
    "                score += 1/math.log(deg)\n",
    "        adamDict[u][v] = score\n",
    "    return adamDict[u][v]\n",
    "\n",
    "def get_att(u,v):\n",
    "    (u,v) = sorted((u,v))\n",
    "    if v not in attDict[u]:\n",
    "        j = nx.preferential_attachment(G_train, [(u, v)])\n",
    "        for x,y,p in j:\n",
    "            attDict[u][v] = p\n",
    "    return attDict[u][v]\n",
    "\n",
    "def get_nbrs(u, v):\n",
    "    (u,v) = sorted((u,v))\n",
    "    if v not in nbrDict[u]:\n",
    "        nbrs = 0\n",
    "        for nbr in nx.common_neighbors(G_train, u, v): nbrs += 1\n",
    "        nbrDict[u][v] = nbrs\n",
    "    return nbrDict[u][v]\n",
    "        \n",
    "def all_pairs(graph):\n",
    "    return chain(graph.edges(), nx.non_edges(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u,v in all_pairs(G_train):\n",
    "    print get_sp(u,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "2000000\n"
     ]
    }
   ],
   "source": [
    "progress = 0\n",
    "\n",
    "for n1, n2 in all_pairs(G_train):\n",
    "    progress += 1\n",
    "    if progress % 1000000 == 0: print progress\n",
    "    get_nbrs(n1, n2)\n",
    "    get_jac(n1, n2)\n",
    "    get_adam2(n1, n2)\n",
    "    get_att(n1, n2)\n",
    "    get_sp(n1, n2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800626 pairs in training set, 29830 edges\n"
     ]
    }
   ],
   "source": [
    "u = []\n",
    "v = []\n",
    "has_links = []\n",
    "jac_co = []\n",
    "adam = []\n",
    "att = []\n",
    "nbrs = []\n",
    "spl = []\n",
    "count = 0\n",
    "for n1, n2 in all_pairs(G_train):\n",
    "    count += 1\n",
    "    u.append(n1)\n",
    "    v.append(n2)\n",
    "    has_links.append(G_train.has_edge(n1,n2))\n",
    "    jac_co.append(get_jac(n1,n2))\n",
    "    adam.append(get_adam2(n1, n2))\n",
    "    att.append(get_att(n1, n2))\n",
    "    nbrs.append(get_nbrs(n1, n2))\n",
    "    spl.append(get_sp(n1, n2))\n",
    "                \n",
    "df_train = pd.DataFrame()\n",
    "df_train['u'] = u\n",
    "df_train['v'] = v\n",
    "df_train['link'] = has_links\n",
    "df_train['jac'] = jac_co\n",
    "df_train['adam'] = adam\n",
    "df_train['nbrs'] = nbrs\n",
    "df_train['att'] = att\n",
    "df_train['spl'] = spl\n",
    "print(\"%d pairs in training set, %d edges\" % (count, np.count_nonzero(has_links)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2770796 pairs in test set, 11205 true edges\n"
     ]
    }
   ],
   "source": [
    "u = []\n",
    "v = []\n",
    "has_links = []\n",
    "jac_co = []\n",
    "adam = []\n",
    "att = []\n",
    "nbrs = []\n",
    "spl = []\n",
    "count = 0\n",
    "\n",
    "for n1, n2 in nx.non_edges(G_train):\n",
    "    u.append(n1)\n",
    "    v.append(n2)\n",
    "    has_links.append(G.has_edge(n1,n2))\n",
    "    jac_co.append(get_jac(n1,n2))\n",
    "    adam.append(get_adam2(n1, n2))\n",
    "    att.append(get_att(n1, n2))\n",
    "    nbrs.append(get_nbrs(n1, n2))\n",
    "    spl.append(get_sp(n1, n2))\n",
    "    count += 1\n",
    "\n",
    "df_test = pd.DataFrame()\n",
    "df_test['u'] = u\n",
    "df_test['v'] = v\n",
    "df_test['link'] = has_links\n",
    "df_test['jac'] = jac_co\n",
    "df_test['adam'] = adam\n",
    "df_test['att'] = att\n",
    "df_test['nbrs'] = nbrs\n",
    "df_test['spl'] = spl\n",
    "print(\"%d pairs in test set, %d true edges\" % (count, np.count_nonzero(has_links)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomfw/Library/Python/2.7/lib/python/site-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000, max_depth=None,\n",
    "    min_samples_split=2, random_state=0, )\n",
    "#rf = SVC(C=.00001, gamma=100, probability=True)\n",
    "fields = ['att']\n",
    "x_train = df_train.loc[:, fields]\n",
    "y_train = np.reshape(df_train.link, (-1, 1))\n",
    "\n",
    "x_test = df_test.loc[:, fields]\n",
    "classifier = rf.fit(x_train, y_train)\n",
    "pred = classifier.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(np.reshape(df_test.link, (-1, 1)), pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1970 predicted... 565 correct\n"
     ]
    }
   ],
   "source": [
    "counts = 0\n",
    "corrects = 0\n",
    "for i in range(0, len(pred[:,1])):\n",
    "    if pred[i,1] > .5:\n",
    "        counts += 1\n",
    "        if G.has_edge(df_test.u[i], df_test.v[i]):\n",
    "            corrects += 1\n",
    "\n",
    "print(\"%d predicted... %d correct\" %(counts, corrects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01594619  0.01594619  0.01594619 ...,  0.00103429  0.00103429\n",
      "  0.00103429]\n"
     ]
    }
   ],
   "source": [
    "print pred[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all information about netwrok\n",
    "## of tweet / time histogram\n",
    "#randomly delete and predict missing edges\n",
    "#epstein KATZ\n",
    "#distribution of degree (log of degree) should look linear\n",
    "#t-SNE\n",
    "#approximate katz"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
