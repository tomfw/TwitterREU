{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import calendar\n",
    "import codecs\n",
    "import datetime\n",
    "import json\n",
    "import sys\n",
    "import gzip\n",
    "import string\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import csv\n",
    "import networkx as nx\n",
    "from demjson import decode\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "globalTweetCounter = 0\n",
    "\n",
    "timeFormat = \"%Y-%m-%dT%H:%M:%S.%fZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countries=['SAfrica-community-relevant-restricted.json']\n",
    "\n",
    "for m in range(len(countries)):\n",
    "    file_string=countries[m]\n",
    "    mypath='/Users/tomfw/Downloads/DataShared/'+file_string\n",
    "    G=nx.Graph()\n",
    "    tweetList = []\n",
    "    timeList = []\n",
    "    userList = []\n",
    "    \n",
    "    with open(mypath) as f1:\n",
    "        for line in f1:\n",
    "           if random.random() < 1.1: # < 1 if you want less data\n",
    "                tweetObj = json.loads(line)\n",
    "                currentTime = datetime.datetime.strptime(tweetObj['postedTime'], timeFormat)\n",
    "                id2=int(re.findall('^.*:([0-9]+)$',str(tweetObj['actor']['id']))[0])\n",
    "                G.add_node(id2, parent=True, child=False)\n",
    "                for ui in tweetObj['twitter_entities']['user_mentions']:\n",
    "                    id1=ui['id']\n",
    "                    G.add_node(id1, child=True)\n",
    "                    G.add_edge(id1,id2, posted=currentTime, message=tweetObj['body'])\n",
    "                    #print id1, id2\n",
    "                try:\n",
    "                    if (not tweetObj['body'].lower().startswith(\"rt\")):\n",
    "                        # Increment tweet count\n",
    "                        globalTweetCounter += 1\n",
    "                        tweetList.append(tweetObj['body'].lower())\n",
    "                        timeList.append(currentTime)\n",
    "                        userList.append(tweetObj['actor']['id'])\n",
    "                        #print globalTweetCounter, tweetObj['body'].lower()\n",
    "                except:\n",
    "                    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-03-15 04:26:31\n",
      "2014-06-13 22:05:22\n"
     ]
    }
   ],
   "source": [
    "print np.min(timeList)\n",
    "print np.max(timeList)\n",
    "split = datetime.datetime(2014, 5, 25) #train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173629 26669 90502\n"
     ]
    }
   ],
   "source": [
    "print G.number_of_edges(), G.number_of_nodes(), len(timeList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for node in G.nodes():\n",
    "    nTrain = 0\n",
    "    nTest = 0\n",
    "    for nbr in G.neighbors(node):\n",
    "        if G.edge[node][nbr]['posted'] < split:\n",
    "            nTrain += 1\n",
    "        else:\n",
    "            nTest += 1\n",
    "    if nTrain < 3 or nTest < 3:\n",
    "        G.remove_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21498 1267\n"
     ]
    }
   ],
   "source": [
    "print G.number_of_edges(), G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "jacDict = {}\n",
    "adamDict = {}\n",
    "nbrDict = {}\n",
    "attDict = {}\n",
    "\n",
    "test_links = {}\n",
    "train_links = {}\n",
    "\n",
    "progress = 0\n",
    "for node in G.nodes():\n",
    "    jacDict[node] = defaultdict(int)\n",
    "    adamDict[node] = defaultdict(int)\n",
    "    nbrDict[node] = defaultdict(int)\n",
    "    attDict[node] = defaultdict(int)\n",
    "    test_links[node] = defaultdict(int)\n",
    "    train_links[node] = defaultdict(int)\n",
    "    \n",
    "for n1 in G.nodes():\n",
    "    progress += 1\n",
    "    if progress % 100 == 0:\n",
    "        print progress\n",
    "    for n2 in G.nodes():\n",
    "        safe = True\n",
    "        j = nx.jaccard_coefficient(G, [(n1, n2)])\n",
    "        ai = nx.adamic_adar_index(G, [(n1, n2)])\n",
    "        pa = nx.preferential_attachment(G, [(n1, n2)])\n",
    "        for nbr in nx.common_neighbors(G, n1,n2):\n",
    "            nbrDict[n1][n2] += 1\n",
    "            nDeg = nx.degree(G, nbr)\n",
    "            if nDeg < 2:\n",
    "                safe = False\n",
    "        for u,v,p in j:\n",
    "            jacDict[n1][n2] = p\n",
    "        if safe:\n",
    "            for u,v,a in ai:\n",
    "                adamDict[n1][n2] = a\n",
    "        for u,v,p in pa:\n",
    "            attDict[n1][n2] = p\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32828 training link, 42591 test links\n"
     ]
    }
   ],
   "source": [
    "G_train = G.copy()\n",
    "for u,v in G_train.edges():\n",
    "    if G_train[u][v]['posted'] > split:\n",
    "        G_train.remove_edge(u,v)\n",
    "        \n",
    "trl = 0\n",
    "tel = 0\n",
    "for n1 in G.nodes():\n",
    "    for n2 in G.nodes():\n",
    "        if G_train.has_edge(n1, n2):\n",
    "            trl += 1\n",
    "            train_links[n1][n2] = 1\n",
    "        if G.has_edge(n1, n2):\n",
    "            tel += 1\n",
    "            test_links[n1][n2] = 1\n",
    "            \n",
    "print(\"%d training link, %d test links\" % (trl, tel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "u = []\n",
    "v = []\n",
    "has_links = []\n",
    "jac_co = []\n",
    "adam = []\n",
    "att = []\n",
    "nbrs = []\n",
    "count = 0\n",
    "for n1 in G_train.nodes():\n",
    "    count += 1\n",
    "    if count % 100 == 0:\n",
    "        print count\n",
    "    for n2 in G_train.nodes():\n",
    "        if n1 != n2:\n",
    "            u.append(n1)\n",
    "            v.append(n2)\n",
    "            has_links.append(train_links[n1][n2])\n",
    "            jac_co.append(jacDict[n1][n2])\n",
    "            adam.append(adamDict[n1][n2])\n",
    "            att.append(attDict[n1][n2])\n",
    "            nbrs.append(nbrDict[n1][n2])\n",
    "df_train = pd.DataFrame()\n",
    "df_train['u'] = u\n",
    "df_train['v'] = v\n",
    "df_train['link'] = has_links\n",
    "df_train['jac'] = jac_co\n",
    "df_train['adam'] = adam\n",
    "df_train['nbrs'] = nbrs\n",
    "df_train['att'] = att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "u = []\n",
    "v = []\n",
    "has_links = []\n",
    "jac_co = []\n",
    "adam = []\n",
    "att = []\n",
    "nbrs = []\n",
    "count = 0\n",
    "for n1 in G.nodes():\n",
    "    count += 1\n",
    "    if count % 100 == 0:\n",
    "        print count\n",
    "    for n2 in G.nodes():\n",
    "        if n1 != n2 and train_links[n1][n2] == 0:\n",
    "            u.append(n1)\n",
    "            v.append(n2)\n",
    "            has_links.append(test_links[n1][n2])\n",
    "            jac_co.append(jacDict[n1][n2])\n",
    "            adam.append(adamDict[n1][n2])\n",
    "            att.append(attDict[n1][n2])\n",
    "            nbrs.append(nbrDict[n1][n2])\n",
    "df_test = pd.DataFrame()\n",
    "df_test['u'] = u\n",
    "df_test['v'] = v\n",
    "df_test['link'] = has_links\n",
    "df_test['jac'] = jac_co\n",
    "df_test['adam'] = adam\n",
    "df_test['att'] = att\n",
    "df_test['nbrs'] = nbrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomfw/Library/Python/2.7/lib/python/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "fields = ['jac', 'att', 'nbrs', 'adam']\n",
    "x_train = df_train.loc[:, fields]\n",
    "#x_train = np.reshape(x_train, (-1, 1))\n",
    "y_train = np.reshape(df_train.loc[:,'link'], (-1, 1))\n",
    "#x_test = np.reshape(df_test.loc[:, fields], (-1, 1))\n",
    "x_test = df_test.loc[:, fields]\n",
    "rf.fit(x_train, y_train)\n",
    "pred = rf.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print pred[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1571514, 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-5e604f5d610a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'link'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    258\u001b[0m     return _average_binary_score(\n\u001b[1;32m    259\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/base.pyc\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         fpr, tpr, tresholds = roc_curve(y_true, y_score,\n\u001b[0;32m--> 255\u001b[0;31m                                         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreorder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \"\"\"\n\u001b[1;32m    504\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 505\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mDecreasing\u001b[0m \u001b[0mscore\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \"\"\"\n\u001b[0;32m--> 297\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 181\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1571514, 2]"
     ]
    }
   ],
   "source": [
    "roc_auc_score(np.reshape(df_test.loc[:,'link'], (-1, 1)), pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
