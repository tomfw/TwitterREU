{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import calendar\n",
    "import codecs\n",
    "import datetime\n",
    "import json\n",
    "import sys\n",
    "import gzip\n",
    "import string\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import csv\n",
    "import networkx as nx\n",
    "from demjson import decode\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "globalTweetCounter = 0\n",
    "\n",
    "timeFormat = \"%Y-%m-%dT%H:%M:%S.%fZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countries=['SAfrica-community-relevant-restricted.json']\n",
    "\n",
    "for m in range(len(countries)):\n",
    "    file_string=countries[m]\n",
    "    mypath='/Users/tomfw/Downloads/DataShared/'+file_string\n",
    "    G=nx.Graph()\n",
    "    tweetList = []\n",
    "    timeList = []\n",
    "    userList = []\n",
    "    \n",
    "    with open(mypath) as f1:\n",
    "        for line in f1:\n",
    "           if random.random() < 1.1: # < 1 if you want less data\n",
    "                tweetObj = json.loads(line)\n",
    "                currentTime = datetime.datetime.strptime(tweetObj['postedTime'], timeFormat)\n",
    "                id2=int(re.findall('^.*:([0-9]+)$',str(tweetObj['actor']['id']))[0])\n",
    "                G.add_node(id2, parent=True, child=False)\n",
    "                for ui in tweetObj['twitter_entities']['user_mentions']:\n",
    "                    id1=ui['id']\n",
    "                    G.add_node(id1, child=True)\n",
    "                    G.add_edge(id1,id2, posted=currentTime, message=tweetObj['body'])\n",
    "                    #print id1, id2\n",
    "                try:\n",
    "                    if (not tweetObj['body'].lower().startswith(\"rt\")):\n",
    "                        # Increment tweet count\n",
    "                        globalTweetCounter += 1\n",
    "                        tweetList.append(tweetObj['body'].lower())\n",
    "                        timeList.append(currentTime)\n",
    "                        userList.append(tweetObj['actor']['id'])\n",
    "                        #print globalTweetCounter, tweetObj['body'].lower()\n",
    "                except:\n",
    "                    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-03-15 04:26:31\n",
      "2014-06-13 22:05:22\n"
     ]
    }
   ],
   "source": [
    "print np.min(timeList)\n",
    "print np.max(timeList)\n",
    "split = datetime.datetime(2014, 5, 25) #train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173629 26669 90502\n"
     ]
    }
   ],
   "source": [
    "print G.number_of_edges(), G.number_of_nodes(), len(timeList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for node in G.nodes():\n",
    "    nTrain = 0\n",
    "    nTest = 0\n",
    "    for nbr in G.neighbors(node):\n",
    "        if G.edge[node][nbr]['posted'] < split:\n",
    "            nTrain += 1\n",
    "        else:\n",
    "            nTest += 1\n",
    "    if nTrain < 3 or nTest < 3:\n",
    "        G.remove_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21498 1267\n"
     ]
    }
   ],
   "source": [
    "print G.number_of_edges(), G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "jacDict = {}\n",
    "adamDict = {}\n",
    "nbrDict = {}\n",
    "attDict = {}\n",
    "\n",
    "test_links = {}\n",
    "train_links = {}\n",
    "\n",
    "progress = 0\n",
    "for node in G.nodes():\n",
    "    jacDict[node] = defaultdict(int)\n",
    "    adamDict[node] = defaultdict(int)\n",
    "    nbrDict[node] = defaultdict(int)\n",
    "    attDict[node] = defaultdict(int)\n",
    "    test_links[node] = defaultdict(int)\n",
    "    train_links[node] = defaultdict(int)\n",
    "    \n",
    "for n1 in G.nodes():\n",
    "    progress += 1\n",
    "    if progress % 100 == 0:\n",
    "        print progress\n",
    "    for n2 in G.nodes():\n",
    "        j = nx.jaccard_coefficient(G, [(n1, n2)])\n",
    "        ai = nx.adamic_adar_index(G, [(n1, n2)])\n",
    "        pa = nx.preferential_attachment(G, [(n1, n2)])\n",
    "        cn = nx.common_neighbors(G, [(n1, n2)])\n",
    "        for u,v,p in j:\n",
    "            jacDict[n1][n2] = p\n",
    "        for u,v,a in ai:\n",
    "            adamDict[n1][n2] = a\n",
    "        for u,v,p in pa:\n",
    "            attDict[n1][n2] = p\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32828 training link, 42591 test links\n"
     ]
    }
   ],
   "source": [
    "G_train = G.copy()\n",
    "for u,v in G_train.edges():\n",
    "    if G_train[u][v]['posted'] > split:\n",
    "        G_train.remove_edge(u,v)\n",
    "        \n",
    "trl = 0\n",
    "tel = 0\n",
    "for n1 in G.nodes():\n",
    "    for n2 in G.nodes():\n",
    "        if G_train.has_edge(n1, n2):\n",
    "            trl += 1\n",
    "            train_links[n1][n2] = 1\n",
    "        if G.has_edge(n1, n2):\n",
    "            tel += 1\n",
    "            test_links[n1][n2] = 1\n",
    "            \n",
    "print(\"%d training link, %d test links\" % (trl, tel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "u = []\n",
    "v = []\n",
    "has_links = []\n",
    "jac_co = []\n",
    "count = 0\n",
    "for n1 in G_train.nodes():\n",
    "    count += 1\n",
    "    if count % 100 == 0:\n",
    "        print count\n",
    "    for n2 in G_train.nodes():\n",
    "        if n1 != n2:\n",
    "            u.append(n1)\n",
    "            v.append(n2)\n",
    "            has_links.append(train_links[n1][n2])\n",
    "            jac_co.append(jacDict[n1][n2])\n",
    "df_train = pd.DataFrame()\n",
    "df_train['u'] = u\n",
    "df_train['v'] = v\n",
    "df_train['link'] = has_links\n",
    "df_train['jac'] = jac_co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "u = []\n",
    "v = []\n",
    "has_links = []\n",
    "jac_co = []\n",
    "count = 0\n",
    "for n1 in G.nodes():\n",
    "    count += 1\n",
    "    if count % 100 == 0:\n",
    "        print count\n",
    "    for n2 in G.nodes():\n",
    "        if n1 != n2 and train_links[n1][n2] == 0:\n",
    "            u.append(n1)\n",
    "            v.append(n2)\n",
    "            has_links.append(test_links[n1][n2])\n",
    "            jac_co.append(jacDict[n1][n2])\n",
    "df_test = pd.DataFrame()\n",
    "df_test['u'] = u\n",
    "df_test['v'] = v\n",
    "df_test['link'] = has_links\n",
    "df_test['jac'] = jac_co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          0\n",
      "1          0\n",
      "2          0\n",
      "3          0\n",
      "4          0\n",
      "5          0\n",
      "6          0\n",
      "7          0\n",
      "8          0\n",
      "9          0\n",
      "10         0\n",
      "11         0\n",
      "12         0\n",
      "13         0\n",
      "14         0\n",
      "15         0\n",
      "16         0\n",
      "17         0\n",
      "18         0\n",
      "19         0\n",
      "20         0\n",
      "21         0\n",
      "22         0\n",
      "23         0\n",
      "24         0\n",
      "25         0\n",
      "26         0\n",
      "27         0\n",
      "28         0\n",
      "29         0\n",
      "          ..\n",
      "1561806    0\n",
      "1561807    0\n",
      "1561808    0\n",
      "1561809    0\n",
      "1561810    0\n",
      "1561811    0\n",
      "1561812    0\n",
      "1561813    0\n",
      "1561814    0\n",
      "1561815    0\n",
      "1561816    0\n",
      "1561817    0\n",
      "1561818    0\n",
      "1561819    0\n",
      "1561820    0\n",
      "1561821    0\n",
      "1561822    0\n",
      "1561823    0\n",
      "1561824    0\n",
      "1561825    0\n",
      "1561826    0\n",
      "1561827    0\n",
      "1561828    0\n",
      "1561829    0\n",
      "1561830    0\n",
      "1561831    0\n",
      "1561832    0\n",
      "1561833    0\n",
      "1561834    0\n",
      "1561835    0\n",
      "Name: link, Length: 1561836, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print df_train.loc[:,'link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomfw/Library/Python/2.7/lib/python/site-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "x_train = df_train.loc[:, 'jac']\n",
    "x_train = np.reshape(x_train, (-1, 1))\n",
    "y_train = np.reshape(df_train.loc[:,'link'], (-1, 1))\n",
    "x_test = np.reshape(df_test.loc[:,'jac'], (-1, 1))\n",
    "rf.fit(x_train, y_train)\n",
    "pred = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1806\n"
     ]
    }
   ],
   "source": [
    "print np.sum(pred)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51959151102700096"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(np.reshape(df_test.loc[:,'link'], (-1, 1)), pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
