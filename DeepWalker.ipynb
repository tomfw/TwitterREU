{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graph.collabgraph import CollabGraph\n",
    "from graph.fbgraph import FBGraph\n",
    "from graph.enrongraph import EnronGraph\n",
    "from graph.twittergraph import TwitterGraph\n",
    "import networkx as nx\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, auc\n",
    "from sklearn.metrics import precision_recall_curve, precision_recall_fscore_support\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = {'southafrica': '0',\n",
    "              'fb': 'FacebookFilteredAdj_90Days_6ActiveTimes_30OutInDeg.mat',\n",
    "              'enron': 'EnronDirectedWithCc_7days.mat',\n",
    "              'collab': 'citation2Filtered.mat'}\n",
    "data_root = '/Volumes/pond/Temp/twitter/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph = CollabGraph.load_collab_graph(data_root + file_names['collab'])\n",
    "# graph = FBGraph.load_fb_graph(data_root + file_names['fb'])\n",
    "graph = EnronGraph.load_enron_graph(data_root + file_names['enron'])\n",
    "# graph = TwitterGraph.rt_graph_from_json(data_root, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 10)\n(10, 20)\n(20, 30)\n(30, 40)\n(40, 50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 60)\n(60, 70)\n(70, 80)\n(80, 90)\n(90, 100)\n(100, 110)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110, 120)\n(120, 130)\n(130, 140)\n(140, 150)\n(150, 160)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 170)\n(170, 180)\n(180, 190)\n19\n15\n5\n22\n36\n51\n97\n185\n180\n273\n410\n452\n456\n562\n623\n614\n799\n518\n88\n22\n"
     ]
    }
   ],
   "source": [
    "sgs = graph.subgraphs_of_length(periods=10)\n",
    "print(len(sgs))\n",
    "for sg in sgs:\n",
    "    print(sg.nx_graph.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 70)\n"
     ]
    }
   ],
   "source": [
    "g_0 = graph.subgraph_within_dates(sgs[0].min_date, sgs[13].max_date)\n",
    "print(sgs[0].min_date, sgs[6].max_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 80)\n(80, 90)\n"
     ]
    }
   ],
   "source": [
    "g_1 = graph.subgraph_within_dates(sgs[14].min_date, sgs[14].max_date)\n",
    "g_2 = graph.subgraph_within_dates(sgs[15].min_date, sgs[15].max_date)\n",
    "print(sgs[7].min_date, sgs[7].max_date)\n",
    "print(sgs[8].min_date, sgs[8].max_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357 edges repeated\n0 timestamps repeated\n"
     ]
    }
   ],
   "source": [
    "repeat_edges = 0\n",
    "repeat_times = 0\n",
    "for u, v, data in g_1.nx_graph.edges_iter(data=True):\n",
    "    if g_0.nx_graph.has_edge(u, v):\n",
    "        repeat_edges += 1\n",
    "        for time in data['timestamps']:\n",
    "            for time2 in g_0.nx_graph.edge[u][v]['timestamps']:\n",
    "                if time == time2:\n",
    "                    repeat_times += 1\n",
    "print(\"%d edges repeated\\n%d timestamps repeated\" % (repeat_edges, repeat_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1370\n614\n799\n"
     ]
    }
   ],
   "source": [
    "print g_0.nx_graph.number_of_edges()\n",
    "print g_1.nx_graph.number_of_edges()\n",
    "print g_2.nx_graph.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.write_edgelist(g_0.nx_graph, 'fb-fucked.edgelist')\n",
    "# g_0.save_edgelist('collab_edges.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dw_predict(prefix, g_0, g_1, g_2, n_files):\n",
    "    for i in range(0, n_files):\n",
    "        f_name = prefix + str(i + 1) + '.txt'\n",
    "        g_0.embeddings = None\n",
    "        g_0.load_embeddings(f_name, 1024)\n",
    "        g_1.embeddings = g_0.embeddings\n",
    "        g_1.emb_cols = g_0.emb_cols\n",
    "\n",
    "        train_pairs = g_0.make_pairs_with_edges(g_1, .5, enforce_has_embeddings=True, enforce_non_edge=False)\n",
    "        test_pairs = g_1.make_pairs_with_edges(g_2, 0, enforce_non_edge=False, enforce_has_embeddings=True)\n",
    "\n",
    "        df_train, y_train = g_0.to_dataframe(pairs=train_pairs, label_graph=g_1)\n",
    "        rf = RandomForestClassifier(n_estimators=1000, max_depth=None, min_samples_split=2, random_state=0, n_jobs=-1)\n",
    "        # rf = SVC(kernel='linear', probability=True)\n",
    "        # rf = AdaBoostClassifier(n_estimators=500)\n",
    "        fields = g_0.emb_cols\n",
    "        x_train = df_train.loc[:, fields]\n",
    "        classifier = rf.fit(x_train, y_train)\n",
    "\n",
    "        df_test, y_test = g_1.to_embedding_dataframe(test_pairs, g_2)\n",
    "\n",
    "        # fields = g_1.emb_cols\n",
    "        x_test = df_test.loc[:, fields]\n",
    "        pred = classifier.predict_proba(x_test)\n",
    "        print(\"Prediction made.... Done\")\n",
    "\n",
    "        #print(roc_auc_score(y_test, pred[:, 1]))\n",
    "        auc = roc_auc_score(y_test, pred[:, 1])\n",
    "        prauc = average_precision_score(y_test, pred[:, 1])\n",
    "        ndcg = ndcg_score(y_test, pred[:, 1], k=50)\n",
    "\n",
    "        print(\"%d / %d: AUC: %.4f PR-AUC: %.4f NDCG: %.4f \" % (i + 1, n_files, auc, prauc, ndcg))\n",
    "\n",
    "        # pr_curve = precision_recall_curve(y_test, pred[:, 1])\n",
    "\n",
    "        # print auc(pr_curve[1], pr_curve[0], reorder=True)\n",
    "        #print average_precision_score(y_test, pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_score(y_true, y_score, k=10, gains=\"exponential\"):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "\n",
    "    if gains == \"exponential\":\n",
    "        gains = 2 ** y_true - 1\n",
    "    elif gains == \"linear\":\n",
    "        gains = y_true\n",
    "    else:\n",
    "        raise ValueError(\"Invalid gains option.\")\n",
    "\n",
    "    # highest rank is 1 so +2 instead of +1\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "\n",
    "def ndcg_score(y_true, y_score, k=10, gains=\"exponential\"):\n",
    "    best = dcg_score(y_true, y_true, k, gains)\n",
    "    actual = dcg_score(y_true, y_score, k, gains)\n",
    "    return actual / best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t739 edges out of 15051 pairs\nPrecomputing katzes....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t1130 pairs checked and 1130 pairs in dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made.... Done\n1 / 10: AUC: 0.8879 PR-AUC: 0.4654 NDCG: 0.7270 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t739 edges out of 15051 pairs\nPrecomputing katzes....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t1130 pairs checked and 1130 pairs in dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made.... Done\n2 / 10: AUC: 0.8885 PR-AUC: 0.4612 NDCG: 0.7086 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t739 edges out of 15051 pairs\nPrecomputing katzes....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t1130 pairs checked and 1130 pairs in dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made.... Done\n3 / 10: AUC: 0.8859 PR-AUC: 0.4487 NDCG: 0.7541 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t739 edges out of 15051 pairs\nPrecomputing katzes....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t1130 pairs checked and 1130 pairs in dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made.... Done\n4 / 10: AUC: 0.8888 PR-AUC: 0.4379 NDCG: 0.6132 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t739 edges out of 15051 pairs\nPrecomputing katzes....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t1130 pairs checked and 1130 pairs in dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made.... Done\n5 / 10: AUC: 0.8910 PR-AUC: 0.4506 NDCG: 0.7651 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t739 edges out of 15051 pairs\nPrecomputing katzes....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t1130 pairs checked and 1130 pairs in dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made.... Done\n6 / 10: AUC: 0.8878 PR-AUC: 0.4454 NDCG: 0.7169 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t739 edges out of 15051 pairs\nPrecomputing katzes....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t1130 pairs checked and 1130 pairs in dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made.... Done\n7 / 10: AUC: 0.8934 PR-AUC: 0.4642 NDCG: 0.8185 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t739 edges out of 15051 pairs\nPrecomputing katzes....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t1130 pairs checked and 1130 pairs in dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made.... Done\n8 / 10: AUC: 0.8864 PR-AUC: 0.4774 NDCG: 0.8083 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t739 edges out of 15051 pairs\nPrecomputing katzes....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t1130 pairs checked and 1130 pairs in dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made.... Done\n9 / 10: AUC: 0.8941 PR-AUC: 0.4529 NDCG: 0.5916 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t739 edges out of 15051 pairs\nPrecomputing katzes....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t1130 pairs checked and 1130 pairs in dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made.... Done\n10 / 10: AUC: 0.8845 PR-AUC: 0.4563 NDCG: 0.7787 \n"
     ]
    }
   ],
   "source": [
    "dw_predict('/Volumes/pond/Temp/walks/enron1024_', g_0, g_1, g_2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t1064 edges out of 216153 pairs\n"
     ]
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing katzes....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t2664 pairs checked and 2664 pairs in dataframe\n"
     ]
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test, y_test = g_1.to_dataframe(pairs=test_pairs, label_graph=g_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made.... Done\n"
     ]
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.903194276162\n"
     ]
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.128433247883\n0.12804152304\n"
     ]
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_labels = []\n",
    "for p in pred[: , 1]:\n",
    "    if p > .5:\n",
    "        bin_labels.append(1)\n",
    "    else:\n",
    "        bin_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.509187074254\n0.822296250805\n"
     ]
    }
   ],
   "source": [
    "pr, re, fs, su = precision_recall_fscore_support(y_test, bin_labels, average='macro')\n",
    "print pr\n",
    "print re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgs = graph.subgraphs_of_length(periods=1)\n",
    "# tg = TwitterGraph.rt_graph_from_json(data_root, 0)\n",
    "# sgs = graph.subgraphs_of_length(days=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sgs' is not defined",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-31afa0ce072a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# confirm that no edge/timestamps are repeated in different subgraphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mn_edges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mn_time_stamps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sgs' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# confirm that no edge/timestamps are repeated in different subgraphs\n",
    "for i, sg in enumerate(sgs):\n",
    "    if i > 0:\n",
    "        n_edges = 0\n",
    "        n_time_stamps = 0\n",
    "        prev = sgs[i - 1]\n",
    "        for u, v, data in prev.nx_graph.edges_iter(data=True):\n",
    "            if sg.nx_graph.has_edge(u, v):\n",
    "                n_edges += 1\n",
    "                for time in data['timestamps']:\n",
    "                    for time2 in sg.nx_graph.edge[u][v]['timestamps']:\n",
    "                        if time == time2:\n",
    "                            n_time_stamps += 1\n",
    "                       # delta = time2 - time\n",
    "                       # if delta.days < .5:\n",
    "                       #     print time, time2, prev.min_date, sg.max_date\n",
    "        print(\"%d - %d\\n\\t%d edges, %d timestamps\" % (i, i -1, n_edges, n_time_stamps))\n",
    "        print(sg.min_date,sg.max_date)\n",
    "        print(prev.min_date,prev.max_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2571\n"
     ]
    }
   ],
   "source": [
    "print sgs[9].nx_graph.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}