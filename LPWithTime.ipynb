{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from itertools import chain\n",
    "import math\n",
    "import twittergraph as tg\n",
    "import ditwittergraph as dtg\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is kind of hacked up... \n",
    "# don't take it too seriously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 181416 tweets\n"
     ]
    }
   ],
   "source": [
    "graph = dtg.LoadTwitterGraph('/Volumes/pond/Temp/twitter/', 0, hashtags=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Date: 2014-06-13 22:05:22\nMin Date: 2014-03-15 04:26:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph edges: 178812\n"
     ]
    }
   ],
   "source": [
    "print(\"Max Date: %s\" % np.max(dtg.timeList))\n",
    "print(\"Min Date: %s\" % np.min(dtg.timeList))\n",
    "print(\"Graph edges: %d\" % graph.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_edges_after(split, g):\n",
    "    new_graph = g.copy()\n",
    "    for u, v in g.edges():\n",
    "        for i in range(0, len(new_graph.edge[u][v]['posted'])):\n",
    "            if new_graph.edge[u][v]['posted'][0] > split:\n",
    "                new_graph.edge[u][v]['posted'].pop(0)\n",
    "                if not new_graph.node[u]['type'] == 'hashtag' and not new_graph.node[v]['type'] == 'hashtag':\n",
    "                    new_graph.edge[u][v]['n_links'] -= 1\n",
    "                else:\n",
    "                    if new_graph.node[u]['type'] == 'hashtag':\n",
    "                        new_graph.node[u]['n_uses'] -= 1\n",
    "                    else:\n",
    "                        new_graph.node[v]['n_uses'] -= 1\n",
    "        if len(new_graph.edge[u][v]['posted']) == 0:\n",
    "            new_graph.remove_edge(u, v)\n",
    "    return new_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New edges in training set: 47877\nNew edges in testing set: 31410\n"
     ]
    }
   ],
   "source": [
    "first_split = datetime.datetime(2014, 5, 5)  #shorten the middle time period because it has more edges\n",
    "second_split = datetime.datetime(2014, 5, 10)\n",
    "\n",
    "g_0 = remove_edges_after(first_split, graph)\n",
    "#tg.remove_degree_zero_nodes(g_0)\n",
    "\n",
    "g_1 = remove_edges_after(second_split, graph)\n",
    "#tg.remove_degree_zero_nodes(g_1)\n",
    "\n",
    "g_2 = graph.copy()\n",
    "print(\"New edges in training set: %d\" % (g_1.number_of_edges() - g_0.number_of_edges()))\n",
    "print(\"New edges in testing set: %d\" % (g_2.number_of_edges() - g_1.number_of_edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 478771\nTest size: 314101\n"
     ]
    }
   ],
   "source": [
    "# only run this if you need a fixed set of pairs to run multiple tests on\n",
    "\n",
    "train_pairs = []\n",
    "test_pairs = []\n",
    "train_dict = defaultdict(bool)\n",
    "test_dict = defaultdict(bool)\n",
    "\n",
    "for u,v in g_1.edges_iter():\n",
    "    if g_1.node[u]['type'] != 'hashtag' and g_1.node[v]['type'] != 'hashtag':\n",
    "        if not g_0.has_edge(u, v) and u in g_0 and v in g_0:\n",
    "            (u, v) = sorted((u, v))\n",
    "            train_pairs.append((u, v))\n",
    "            train_dict[(u, v)] = True\n",
    "n_pairs = len(train_pairs)\n",
    "target = 10 * n_pairs\n",
    "for u, v in nx.non_edges(g_0):\n",
    "    u, v = sorted((u, v))\n",
    "    if not train_dict[(u, v)]:\n",
    "        train_dict[(u, v)] = True\n",
    "        train_pairs.append((u, v))\n",
    "        n_pairs += 1\n",
    "    if n_pairs > target:\n",
    "        break\n",
    "\n",
    "for u,v in g_2.edges_iter():\n",
    "    if g_2.node[u]['type'] != 'hashtag' and g_2.node[v]['type'] != 'hashtag':\n",
    "        if not g_1.has_edge(u, v) and u in g_1 and v in g_1:\n",
    "            (u, v) = sorted((u, v))\n",
    "            test_pairs.append((u, v))\n",
    "            test_dict[(u, v)] = True\n",
    "n_pairs = len(test_pairs)\n",
    "target = 10 * n_pairs\n",
    "for u, v in nx.non_edges(g_1):\n",
    "    u, v = sorted((u, v))\n",
    "    if not test_dict[(u, v)]:\n",
    "        test_dict[(u, v)] = True\n",
    "        test_pairs.append((u, v))\n",
    "        n_pairs += 1\n",
    "    if n_pairs > target:\n",
    "        break\n",
    "\n",
    "\n",
    "del train_dict\n",
    "del test_dict\n",
    "\n",
    "print(\"Train size: %d\" % len(train_pairs))\n",
    "print(\"Test size: %d\" % len(test_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing katzes....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000 checked... 976325 eliminated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000000 checked... 1952124 eliminated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000 checked... 2930663 eliminated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000000 checked... 3909326 eliminated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000000 checked... 4886187 eliminated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5022300 pairs checked and 114132 pairs in dataframe\nPrecomputing katzes....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000 checked... 979837 eliminated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000000 checked... 1961311 eliminated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000 checked... 2943376 eliminated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556606 pairs checked and 67086 pairs in dataframe\n"
     ]
    }
   ],
   "source": [
    "df_train, y_train = dtg.dataframe_from_graph(g_0, pairs=False, sampling=0.007, label_graph=g_1, min_katz=0.0069, cheat=True)\n",
    "#y_train = dtg.labels_for_dataframe(df_train, g_1)\n",
    "\n",
    "df_test, y_test = dtg.dataframe_from_graph(g_1, pairs=False, sampling=0.005, label_graph=g_2, min_katz=0.0069, cheat=False)\n",
    "#y_test = dtg.labels_for_dataframe(df_test, g_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 27144 new edges out of 114132 pairs \nTesting on 75 new edges out of 67086 pairs\n"
     ]
    }
   ],
   "source": [
    "print(\"Training on %d new edges out of %d pairs \" % (np.sum(y_train), df_train.shape[0]))\n",
    "print(\"Testing on %d new edges out of %d pairs\" % (np.sum(y_test), df_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=500, max_depth=None, min_samples_split=2, random_state=0, n_jobs=-1)\n",
    "# rf = LinearSVC()\n",
    "fields = ['katz', 'att', 'adam', 'jac',  'nbrs', 'spl']\n",
    "x_train = df_train.loc[:, fields]\n",
    "x_test = df_test.loc[:, fields]\n",
    "\n",
    "classifier = rf.fit(x_train, y_train)\n",
    "pred = classifier.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bin_pred = []\n",
    "for i in range(len(pred)):\n",
    "    if pred[i, 1] > .5:\n",
    "        bin_pred.append(True)\n",
    "    else:\n",
    "        bin_pred.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.779519083931\n0.716604139619\n5855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomfw/anaconda/lib/python2.7/site-packages/numpy/lib/function_base.py:1768: DeprecationWarning: numpy boolean subtract, the `-` operator, is deprecated, use the bitwise_xor, the `^` operator, or the logical_xor function instead.\n  return a[slice1]-a[slice2]\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_test, pred[:, 1]))\n",
    "print(roc_auc_score(y_test, bin_pred))\n",
    "print(np.sum(bin_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0067\nRecall: 0.5200\nF-Score: 0.0132\n"
     ]
    }
   ],
   "source": [
    "(pr, re, fs, su) = precision_recall_fscore_support(y_test, bin_pred, average='binary')\n",
    "print(\"Precision: %.4f\" % pr)\n",
    "print(\"Recall: %.4f\" % re)\n",
    "print(\"F-Score: %.4f\" % fs)\n",
    "# print(\"Support: %.4f\" % su)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we force all new edges into the test set:\n",
    "# precision: .6375\n",
    "# recall : .7265\n",
    "# f-score: .6791"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['katz', 'att', 'adam', 'jac', 'nbrs', 'spl']\n[ 0.65054065  0.11734339  0.0643053   0.06629594  0.01470793  0.08680679]\n"
     ]
    }
   ],
   "source": [
    "print fields\n",
    "print rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions: 61234\nIncorrect predictions: 5852\n\n39 true positive\n36 false negative\n5816 false positives\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "incorrect = 0\n",
    "correct_edges = 0\n",
    "incorrect_edges = 0\n",
    "false_positive = 0\n",
    "false_negative = 0\n",
    "\n",
    "for i in range(0,df_test.shape[0]):\n",
    "    prediction = bin_pred[i]\n",
    "    actu = y_test[i]\n",
    "    if prediction == actu:\n",
    "        correct += 1\n",
    "        if actu:\n",
    "            correct_edges += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "        if actu:\n",
    "            incorrect_edges += 1\n",
    "        else:\n",
    "            false_positive += 1\n",
    "\n",
    "print(\"Correct predictions: %d\" % correct)\n",
    "print(\"Incorrect predictions: %d\\n\" % incorrect)\n",
    "\n",
    "print(\"%d true positive\" % correct_edges)\n",
    "print(\"%d false negative\" % incorrect_edges)\n",
    "print(\"%d false positives\" % false_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}