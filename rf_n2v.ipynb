{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from graph.twittergraph import TwitterGraph as tg\n",
    "from graph.graph import Graph\n",
    "import os\n",
    "import subprocess\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tg.rt_graph_from_json('/Users/tomfw/Downloads/DataShared/', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/Users/tomfw/Desktop/temp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made 13 graphs.\n"
     ]
    }
   ],
   "source": [
    "sgs = graph.subgraphs_of_length(7)\n",
    "print(\"Made %d graphs.\" % len(sgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 3315 edges,  20718 nodes\n1: 1917 edges,  20718 nodes\n2: 3528 edges,  20718 nodes\n3: 4479 edges,  20718 nodes\n4: 6799 edges,  20718 nodes\n5: 4544 edges,  20718 nodes\n6: 6528 edges,  20718 nodes\n7: 24124 edges,  20718 nodes\n8: 4566 edges,  20718 nodes"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n9: 2839 edges,  20718 nodes\n10: 2349 edges,  20718 nodes\n11: 1792 edges,  20718 nodes\n12: 1081 edges,  20718 nodes\n\nOriginal graph edges: 58193\nSum of edges  in subgraphs: 67861\n"
     ]
    }
   ],
   "source": [
    "edges = 0\n",
    "for i, sg in enumerate(sgs):\n",
    "    e = sg.nx_graph.number_of_edges()\n",
    "    edges += e\n",
    "    print(\"%d: %d edges,  %d nodes\" % (i, e, sg.nx_graph.number_of_nodes()))\n",
    "print(\"\\nOriginal graph edges: %d\\nSum of edges  in subgraphs: %d\" % (graph.nx_graph.number_of_edges(), edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 56 core nodes.\n"
     ]
    }
   ],
   "source": [
    "core_nodes = []\n",
    "prev_embeds = []  # subgraphs * len(core_nodes)\n",
    "for _ in sgs:\n",
    "    prev_embeds.append([])\n",
    "for node in graph.nx_graph.nodes_iter():\n",
    "    is_core = True\n",
    "    for sg in sgs:\n",
    "        if sg.nx_graph.degree(node) == 0:\n",
    "            is_core = False\n",
    "    if is_core:\n",
    "        core_nodes.append(node)\n",
    "            \n",
    "print(\"Found %d core nodes.\" % len(core_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_core_embeds(embed_dict):\n",
    "    embeds = []\n",
    "    for node in core_nodes:\n",
    "        embeds.append(embed_dict[node])\n",
    "    return embeds\n",
    "\n",
    "\n",
    "def core_movement(embed_dict):\n",
    "    dist = 0\n",
    "    for i, node in enumerate(core_nodes):\n",
    "        dist += embedding_distance(prev_embeds[i], embed_dict[node])\n",
    "    return dist\n",
    "\n",
    "\n",
    "def embedding_distance(x1, x2):\n",
    "    d = 0\n",
    "    for x, y in zip(x1, x2):\n",
    "        d += (x - y) ** 2\n",
    "    return np.sqrt(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_path = '/Users/tomfw/Downloads/temporalnode2vec/lineLinux/line'\n",
    "rf_path = '/Users/tomfw/Downloads/temporalnode2vec/word2vec/retrofit_word2vec_one'\n",
    "n2v_path = '/Users/tomfw/Desktop/snap/examples/node2vec/node2vec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_command(train, output, size=128, threads=8, negative=5):\n",
    "    # todo: order, rho, etc...\n",
    "    command = [line_path, \"-train\", train, \"-output\",  output, \"-size\", str(size), \"-threads\", str(threads),\n",
    "               \"-negative\", str(negative)]\n",
    "    return command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_command(input, output, init, beta_file, size=128, window=5, sample=0, negative=5, threads=8, beta=1):\n",
    "    command = [rf_path,\"-train\", input, \"-init\", init, \"-output\", output,\n",
    "               \"-size\", str(size), \"-window\", str(window), \"-sample\", str(sample),\n",
    "               \"-negative\", str(negative), \"-threads\", str(threads), \"-beta\", str(beta), \"-cbow\", '0']\n",
    "    return command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n2v_command(edge_file, output, n_walks=10, walk_length=50, p=1, q=1):\n",
    "    command = [n2v_path, '-i:' + edge_file, '-o:' + output, '-p:' + str(p), '-q:' + str(q),\n",
    "               '-r:' + str(n_walks), '-l:' + str(walk_length), '-w', '1', '-v', '1']\n",
    "    return command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_command(command):\n",
    "    process = subprocess.Popen(command, stderr=subprocess.PIPE)\n",
    "    err = process.communicate()\n",
    "    if err[0]:\n",
    "        print err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time period: (1/13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoaded embeddings. Dimensions: (2559, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time period: (2/13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tWalking...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUpdating embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMerging updated embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoaded embeddings. Dimensions: (3496, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tDistance this iteration: 5.1637\nCurrent time period: (3/13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tWalking...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUpdating embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMerging updated embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoaded embeddings. Dimensions: (5037, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tDistance this iteration: 4.0208\nCurrent time period: (4/13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tWalking...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUpdating embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMerging updated embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoaded embeddings. Dimensions: (6543, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tDistance this iteration: 4.0508\nCurrent time period: (5/13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFit 4-9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFound 16027 new edges out of 32054 total pairs\n\tUsing the pairs you provided...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t32054 pairs checked and 32054 pairs in dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tModel fitted\n\tWalking...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUpdating embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMerging updated embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoaded embeddings. Dimensions: (8288, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tDistance this iteration: 3.7371\nCurrent time period: (6/13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tWalking...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUpdating embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMerging updated embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoaded embeddings. Dimensions: (9442, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tDistance this iteration: 3.7387\nCurrent time period: (7/13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tWalking...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUpdating embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMerging updated embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoaded embeddings. Dimensions: (11063, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tDistance this iteration: 3.1477\nCurrent time period: (8/13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tWalking...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUpdating embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMerging updated embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoaded embeddings. Dimensions: (16387, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tDistance this iteration: 3.4984\nCurrent time period: (9/13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTesting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFound 8766 new edges out of 17532 total pairs\n\tUsing the pairs you provided...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t17532 pairs checked and 17532 pairs in dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made.... Done\n"
     ]
    }
   ],
   "source": [
    "embed_file = data_folder + 'embeddings.txt'\n",
    "walk_file = data_folder + 'walks.txt'\n",
    "init_file = data_folder + 'init.txt'\n",
    "beta_file = data_folder + 'betas.txt'\n",
    "edge_file = data_folder + 'e_list.txt'\n",
    "\n",
    "\n",
    "emb_command = rf_command(walk_file, embed_file, init_file, beta_file, beta=15)\n",
    "walk_command = n2v_command(edge_file, walk_file, p=1, q=1)\n",
    "classifier = None\n",
    "pred = None\n",
    "for i, sg in enumerate(sgs):\n",
    "    print(\"Current time period: (%d/%d)\" % (i + 1, len(sgs)))\n",
    "    cum = graph.subgraph_within_dates(sgs[0].min_date, sg.max_date).nx_graph\n",
    "\n",
    "    sg.save_edgelist(edge_file)\n",
    "    if i == 0:\n",
    "        run_command(line_command(edge_file, output=embed_file))\n",
    "        sg.load_embeddings(embed_file)\n",
    "        sg.save_embeddings(init_file, 128)\n",
    "        prev_embeds = store_core_embeds(sg.embeddings)\n",
    "    else:\n",
    "        prev = sgs[i - 1]\n",
    "        if i == 4:\n",
    "            print(\"\\tFit 4-9\")\n",
    "            train_graph = graph.subgraph_within_dates(sg.min_date, sgs[i + 4].max_date)\n",
    "            train_graph.embeddings = prev.embeddings\n",
    "            train_graph.emb_cols = prev.emb_cols\n",
    "            train_pairs = prev.make_pairs_with_edges(train_graph, .5, enforce_non_edge=False, enforce_has_embeddings=True)\n",
    "            df_train, y_train = prev.to_dataframe(pairs=train_pairs, label_graph=train_graph)\n",
    "            rf = RandomForestClassifier(n_estimators=500, max_depth=None, min_samples_split=2, random_state=0, n_jobs=-1)\n",
    "            fields = prev.emb_cols\n",
    "            x_train = df_train.loc[:, fields]\n",
    "            classifier = rf.fit(x_train, y_train)\n",
    "            print(\"\\tModel fitted\")\n",
    "        if i == 8:\n",
    "            print(\"\\tTesting...\")\n",
    "            test_graph = graph.subgraph_within_dates(sg.min_date, sgs[i+4].max_date)\n",
    "            test_graph.embeddings = prev.embeddings\n",
    "            test_graph.emb_cols = prev.emb_cols\n",
    "            test_pairs = prev.make_pairs_with_edges(test_graph, .5, enforce_non_edge=False, enforce_has_embeddings=True)\n",
    "            df_test, y_test = prev.to_dataframe(test_pairs, label_graph=test_graph)\n",
    "            fields = prev.emb_cols\n",
    "            x_test = df_test.loc[:, fields]\n",
    "            pred = classifier.predict_proba(x_test)\n",
    "            print(\"Prediction made.... Done\")\n",
    "            break\n",
    "        sg.generate_embeddings_with_prev(prev.embeddings, 128)\n",
    "        print(\"\\tWalking...\")\n",
    "        run_command(walk_command)\n",
    "        print(\"\\tUpdating embeddings...\")\n",
    "        run_command(emb_command)\n",
    "        print(\"\\tMerging updated embeddings\")\n",
    "        sg.load_embeddings(embed_file)  # update embeddings with output from w2v\n",
    "        sg.save_embeddings(init_file, 128)\n",
    "        distance = core_movement(sg.embeddings)\n",
    "        prev_embeds = store_core_embeds(sg.embeddings)\n",
    "        print(\"\\tDistance this iteration: %.4f\" % distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.879362304496\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print roc_auc_score(y_test, pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = sgs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = []\n",
    "for _ in g1.emb_cols:\n",
    "    emb.append([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n128\n"
     ]
    }
   ],
   "source": [
    "print len(g1.embeddings[5])\n",
    "print len(emb)\n",
    "emb = np.stack((g1.embeddings[2], g1.embeddings[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "print len(emb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "print len(np.mean((g1.embeddings[2], g1.embeddings[5]), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}