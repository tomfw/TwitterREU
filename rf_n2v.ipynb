{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from graph.twittergraph import TwitterGraph as tg\n",
    "from graph.graph import Graph\n",
    "from graph.enrongraph import EnronGraph as eg\n",
    "from graph.fbgraph import FBGraph as fb\n",
    "from graph.collabgraph import CollabGraph as cg\n",
    "import os\n",
    "import subprocess\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score, ndcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph = tg.rt_graph_from_json('/Users/tomfw/Downloads/DataShared/', 0)\n",
    "graph = eg.load_enron_graph('/Users/tomfw/Downloads/Data/Enron/EnronDirectedWithCc_7days.mat')\n",
    "# graph = fb.load_fb_graph('/Users/tomfw/Downloads/Data/Facebook/FacebookFilteredAdj_90Days_6ActiveTimes_30OutInDeg.mat')\n",
    "# graph = cg.load_collab_graph('/Users/tomfw/Downloads/Data/DBLP2/citation2Filtered.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collab .83\n",
    "#facebook .90\n",
    "#enron .60\n",
    "#S Africa .88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/Users/tomfw/Desktop/temp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made 9 graphs.\n"
     ]
    }
   ],
   "source": [
    "sgs = graph.subgraphs_of_length(periods=21)\n",
    "print(\"Made %d graphs.\" % len(sgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 15 edges,  182 nodes\n1: 50 edges,  182 nodes\n2: 172 edges,  182 nodes\n3: 315 edges,  182 nodes\n4: 580 edges,  182 nodes\n5: 713 edges,  182 nodes\n6: 1044 edges,  182 nodes\n7: 1055 edges,  182 nodes\n8: 298 edges,  182 nodes\n\nOriginal graph edges: 2097\nSum of edges  in subgraphs: 4242\n"
     ]
    }
   ],
   "source": [
    "edges = 0\n",
    "for i, sg in enumerate(sgs):\n",
    "    e = sg.nx_graph.number_of_edges()\n",
    "    edges += e\n",
    "    print(\"%d: %d edges,  %d nodes\" % (i, e, sg.nx_graph.number_of_nodes()))\n",
    "print(\"\\nOriginal graph edges: %d\\nSum of edges  in subgraphs: %d\" % (graph.nx_graph.number_of_edges(), edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 core nodes.\n"
     ]
    }
   ],
   "source": [
    "core_nodes = []\n",
    "prev_embeds = []  # subgraphs * len(core_nodes)\n",
    "for _ in sgs:\n",
    "    prev_embeds.append([])\n",
    "for node in graph.nx_graph.nodes_iter():\n",
    "    is_core = True\n",
    "    for sg in sgs:\n",
    "        if sg.nx_graph.degree(node) == 0:\n",
    "            is_core = False\n",
    "    if is_core:\n",
    "        core_nodes.append(node)\n",
    "            \n",
    "print(\"Found %d core nodes.\" % len(core_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_core_embeds(embed_dict):\n",
    "    embeds = []\n",
    "    for node in core_nodes:\n",
    "        embeds.append(embed_dict[node])\n",
    "    return embeds\n",
    "\n",
    "\n",
    "def core_movement(embed_dict):\n",
    "    dist = 0\n",
    "    for i, node in enumerate(core_nodes):\n",
    "        dist += embedding_distance(prev_embeds[i], embed_dict[node])\n",
    "    return dist\n",
    "\n",
    "\n",
    "def embedding_distance(x1, x2):\n",
    "    d = 0\n",
    "    for x, y in zip(x1, x2):\n",
    "        d += (x - y) ** 2\n",
    "    return np.sqrt(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_path = '/Users/tomfw/Downloads/temporalnode2vec/lineLinux/line'\n",
    "rf_path = '/Users/tomfw/Downloads/temporalnode2vec/word2vec/retrofit_word2vec_one'\n",
    "n2v_path = '/Users/tomfw/Desktop/snap/examples/node2vec/node2vec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_command(train, output, size=128, threads=8, negative=5):\n",
    "    # todo: order, rho, etc...\n",
    "    command = [line_path, \"-train\", train, \"-output\",  output, \"-size\", str(size), \"-threads\", str(threads),\n",
    "               \"-negative\", str(negative)]\n",
    "    return command\n",
    "\n",
    "def rf_command(input, output, init, beta_file, size=128, window=5, sample=0, negative=5, threads=8, beta=1):\n",
    "    command = [rf_path,\"-train\", input, \"-init\", init, \"-output\", output,\n",
    "               \"-size\", str(size), \"-window\", str(window), \"-sample\", str(sample),\n",
    "               \"-negative\", str(negative), \"-threads\", str(threads), \"-beta\", str(beta), \"-cbow\", '0']\n",
    "    return command\n",
    "\n",
    "def n2v_command(edge_file, output, n_walks=10, walk_length=50, p=1, q=1):\n",
    "    command = [n2v_path, '-i:' + edge_file, '-o:' + output, '-p:' + str(p), '-q:' + str(q),\n",
    "               '-r:' + str(n_walks), '-l:' + str(walk_length), '-w', '1', '-v', '1']\n",
    "    return command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_command(command):\n",
    "    process = subprocess.Popen(command, stderr=subprocess.PIPE)\n",
    "    err = process.communicate()\n",
    "    if err[0]:\n",
    "        print err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time period: (1/9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoaded embeddings. Dimensions: (14, 128)\nCurrent time period: (2/9)\n\tWalking...\n\tUpdating embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMerging updated embeddings\n\tLoaded embeddings. Dimensions: (31, 128)\n\tDistance this iteration: 14.3636\nCurrent time period: (3/9)\n\tWalking...\n\tUpdating embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMerging updated embeddings\n\tLoaded embeddings. Dimensions: (83, 128)\n\tDistance this iteration: 2.4571\nCurrent time period: (4/9)\n\tWalking...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUpdating embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMerging updated embeddings\n\tLoaded embeddings. Dimensions: (115, 128)\n\tDistance this iteration: 2.8221\nCurrent time period: (5/9)\n\tFit...\n\tFound 1018 new edges out of 2036 total pairs\n\tUsing the pairs you provided...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t2036 pairs checked and 2036 pairs in dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tModel fitted\n\tWalking...\n\tUpdating embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMerging updated embeddings\n\tLoaded embeddings. Dimensions: (138, 128)\n\tDistance this iteration: 3.7181\nCurrent time period: (6/9)\n\tWalking...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUpdating embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMerging updated embeddings\n\tLoaded embeddings. Dimensions: (148, 128)\n\tDistance this iteration: 2.1429\nCurrent time period: (7/9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTesting...\n\tFound 1096 new edges out of 2192 total pairs\n\tUsing the pairs you provided...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t2192 pairs checked and 2192 pairs in dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made.... Done\n"
     ]
    }
   ],
   "source": [
    "embed_file = data_folder + 'embeddings.txt'\n",
    "walk_file = data_folder + 'walks.txt'\n",
    "init_file = data_folder + 'init.txt'\n",
    "beta_file = data_folder + 'betas.txt'\n",
    "edge_file = data_folder + 'e_list.txt'\n",
    "\n",
    "\n",
    "emb_command = rf_command(walk_file, embed_file, init_file, beta_file, beta=1)\n",
    "walk_command = n2v_command(edge_file, walk_file, p=1, q=1, n_walks=10, walk_length=50)\n",
    "classifier = None\n",
    "pred = None\n",
    "for i, sg in enumerate(sgs):\n",
    "    print(\"Current time period: (%d/%d)\" % (i + 1, len(sgs)))\n",
    "    cum = graph.subgraph_within_dates(sgs[0].min_date, sg.max_date).nx_graph\n",
    "\n",
    "    sg.save_edgelist(edge_file)\n",
    "    if i == 0:\n",
    "        run_command(line_command(edge_file, output=embed_file))\n",
    "        sg.load_embeddings(embed_file)\n",
    "        sg.save_embeddings(init_file, 128)\n",
    "        prev_embeds = store_core_embeds(sg.embeddings)\n",
    "    else:\n",
    "        prev = sgs[i - 1]\n",
    "        if i == 4:\n",
    "            print(\"\\tFit...\")\n",
    "            train_graph = graph.subgraph_within_dates(sg.min_date, sgs[i + 2].max_date)\n",
    "            train_graph.embeddings = prev.embeddings\n",
    "            train_graph.emb_cols = prev.emb_cols\n",
    "            train_pairs = prev.make_pairs_with_edges(train_graph, .5, enforce_non_edge=False, enforce_has_embeddings=True)\n",
    "            df_train, y_train = prev.to_dataframe(pairs=train_pairs, label_graph=train_graph)\n",
    "            rf = RandomForestClassifier(n_estimators=500, max_depth=None, min_samples_split=2, random_state=0, n_jobs=-1)\n",
    "            fields = prev.emb_cols\n",
    "            x_train = df_train.loc[:, fields]\n",
    "            classifier = rf.fit(x_train, y_train)\n",
    "            print(\"\\tModel fitted\")\n",
    "        if i == 6:\n",
    "            print(\"\\tTesting...\")\n",
    "            test_graph = graph.subgraph_within_dates(sg.min_date, sgs[i+2].max_date)\n",
    "            test_graph.embeddings = prev.embeddings\n",
    "            test_graph.emb_cols = prev.emb_cols\n",
    "            test_pairs = prev.make_pairs_with_edges(test_graph, .5, enforce_non_edge=False, enforce_has_embeddings=True)\n",
    "            df_test, y_test = prev.to_dataframe(test_pairs, label_graph=test_graph)\n",
    "            fields = prev.emb_cols\n",
    "            x_test = df_test.loc[:, fields]\n",
    "            pred = classifier.predict_proba(x_test)\n",
    "            print(\"Prediction made.... Done\")\n",
    "            break\n",
    "        sg.generate_embeddings_with_prev(prev.embeddings, 128)\n",
    "        run_command(walk_command)\n",
    "        run_command(emb_command)\n",
    "        sg.load_embeddings(embed_file)  # update embeddings with output from w2v\n",
    "        sg.save_embeddings(init_file, 128)\n",
    "        distance = core_movement(sg.embeddings)\n",
    "        prev_embeds = store_core_embeds(sg.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.6182\nPR-AUC: 0.6100\nNDCG: 0.7485\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"AUC: %.4f\" % roc_auc_score(y_test, pred[:, 1]))\n",
    "print(\"PR-AUC: %.4f\" % average_precision_score(y_test, pred[:, 1], average='macro'))\n",
    "print(\"NDCG: %.4f\" % ndcg_at_k(pred[:,1], 100))\n",
    "#bin = [int(x) for x in y_test]\n",
    "#predicted =[]\n",
    "#for i in range(0, pred.shape[0]):\n",
    "#    predicted.append([pred[i, 0], pred[i, 1]])\n",
    "#print(\"NDCG: %.4f\" % ndcg_score(bin, predicted,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(r, k, method=0):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0.\n",
    "\n",
    "\n",
    "def ndcg_at_k(r, k, method=0):\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k, method) / dcg_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for node in graph.nx_graph.nodes_iter():\n",
    "#     print(\"%d\")\n",
    "#     for u, v in graph.nx_graph.edges(node):\n",
    "#         print(\"\\t%d, %d\" % (u , v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}