{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from twittergraph import TwitterGraph as tg\n",
    "import os\n",
    "import subprocess\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tg.rt_graph_from_json('/Users/tomfw/Downloads/DataShared/', 0)\n",
    "data_folder = '/Users/tomfw/TwitterREU/temp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph.save_edgelist('/Users/tomfw/Desktop/graph_rt_sa_full.edgelist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made 13 graphs.\n"
     ]
    }
   ],
   "source": [
    "sgs = graph.subgraphs_of_length(7)\n",
    "print(\"Made %d graphs.\" % len(sgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 3315 edges,  20718 nodes\n1: 1917 edges,  20718 nodes\n2: 3528 edges,  20718 nodes\n3: 4479 edges,  20718 nodes\n4: 6799 edges,  20718 nodes"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n5: 4544 edges,  20718 nodes\n6: 6528 edges,  20718 nodes\n7: 24124 edges,  20718 nodes\n8: 4566 edges,  20718 nodes\n9: 2839 edges,  20718 nodes\n10: 2349 edges,  20718 nodes\n11: 1792 edges,  20718 nodes\n12: 1081 edges,  20718 nodes\n\nOriginal graph edges: 58193\nSum of edges  in subgraphs: 67861\n"
     ]
    }
   ],
   "source": [
    "edges = 0\n",
    "for i, sg in enumerate(sgs):\n",
    "    e = sg.nx_graph.number_of_edges()\n",
    "    edges += e\n",
    "    print(\"%d: %d edges,  %d nodes\" % (i, e, sg.nx_graph.number_of_nodes()))\n",
    "print(\"\\nOriginal graph edges: %d\\nSum of edges  in subgraphs: %d\" % (graph.nx_graph.number_of_edges(), edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 56 core nodes.\n"
     ]
    }
   ],
   "source": [
    "core_nodes = []\n",
    "prev_embeds = [] # subgraphs * len(core_nodes)\n",
    "for _ in sgs:\n",
    "    prev_embeds.append([])\n",
    "for node in graph.nx_graph.nodes_iter():\n",
    "    is_core = True\n",
    "    for sg in sgs:\n",
    "        if sg.nx_graph.degree(node) == 0:\n",
    "            is_core = False\n",
    "    if is_core:\n",
    "        core_nodes.append(node)\n",
    "            \n",
    "print(\"Found %d core nodes.\" % len(core_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_core_embeds(embed_dict):\n",
    "    embeds = []\n",
    "    for node in core_nodes:\n",
    "        embeds.append(embed_dict[node])\n",
    "    return embeds\n",
    "\n",
    "def core_movement(embed_dict):\n",
    "    dist = 0\n",
    "    for i, node in enumerate(core_nodes):\n",
    "        dist += embedding_distance(prev_embeds[i], embed_dict[node])\n",
    "    return dist\n",
    "\n",
    "def embedding_distance(x1, x2):\n",
    "    d = 0\n",
    "    for x, y in zip(x1, x2):\n",
    "        d += (x - y) ** 2\n",
    "    return np.sqrt(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_path = '/Users/tomfw/Downloads/temporalnode2vec/lineLinux/line'\n",
    "rf_path = '/Users/tomfw/Downloads/temporalnode2vec/word2vec/retrofit_word2vec_one'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_command(train, output, size=128, threads=8, negative=5):\n",
    "    # todo: order, rho, etc...\n",
    "    command = [line_path, \"-train\", train, \"-output\",  output, \"-size\", str(size), \"-threads\", str(threads),\n",
    "               \"-negative\", str(negative)]\n",
    "    return command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_command(input, output, init, beta_file, size=128, window=5, sample=0, negative=5, threads=8, beta=1):\n",
    "    command = [rf_path,\"-train\", input, \"-init\", init, \"-output\", output,\n",
    "               \"-size\", str(size), \"-window\", str(window), \"-sample\", str(sample),\n",
    "               \"-negative\", str(negative), \"-threads\", str(threads), \"-beta\", str(beta),\n",
    "               \"-beta-file\", beta_file, \"-cbow\", '0']\n",
    "    return command\n",
    "\n",
    "def clear_data():\n",
    "    process = subprocess.Popen(['/bin/rm', '-rf', data_folder + '*'], stderr=subprocess.PIPE)\n",
    "    err = process.communicate()\n",
    "    print err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings. Dimensions: (16387, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing walks.....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings. Dimensions: (16387, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance this iteration: 21.4467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing walks.....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings. Dimensions: (16387, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance this iteration: 18.1561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing walks.....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings. Dimensions: (16387, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance this iteration: 18.7076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit 4-9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41312 new edges out of 82625 total pairs\nUsing the pairs you provided...\nPrecomputing katzes....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82625 pairs checked and 82625 pairs in dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing walks.....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings. Dimensions: (16387, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance this iteration: 16.8162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing walks.....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings. Dimensions: (16387, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance this iteration: 17.2393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing walks.....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings. Dimensions: (16387, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance this iteration: 15.9404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing walks.....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 10001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings. Dimensions: (16387, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance this iteration: 18.5819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8766 new edges out of 17533 total pairs\nUsing the pairs you provided...\nPrecomputing katzes....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17533 pairs checked and 17533 pairs in dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made.... Done\n"
     ]
    }
   ],
   "source": [
    "embed_file = data_folder + 'embeddings.txt'\n",
    "walk_file = data_folder + 'walks.txt'\n",
    "init_file = data_folder + 'init.txt'\n",
    "beta_file = data_folder + 'betas.txt'\n",
    "\n",
    "emb_command = rf_command(walk_file, embed_file, init_file, beta_file, beta=0.8)\n",
    "\n",
    "classifier = None\n",
    "pred = None\n",
    "for i, sg in enumerate(sgs):\n",
    "    cum = graph.subgraph_within_dates(sgs[0].min_date, sg.max_date).nx_graph\n",
    "\n",
    "    if i == 0:\n",
    "        edge_file = data_folder + 'e_list.txt'\n",
    "        sg.save_edgelist(edge_file)\n",
    "        command = line_command(edge_file, output=embed_file)\n",
    "        process = subprocess.Popen(command, stderr=subprocess.PIPE)\n",
    "        err = process.communicate()\n",
    "        if err[0]:\n",
    "            print err\n",
    "        sg.load_embeddings(embed_file)\n",
    "        sg.save_betas(beta_file, degree_graph=cum)\n",
    "        sg.save_embeddings(init_file, 128)\n",
    "        prev_embeds = store_core_embeds(sg.embeddings)\n",
    "    else:\n",
    "        prev = sgs[i - 1]\n",
    "        if i == 4:\n",
    "            print(\"Fit 4-9\")\n",
    "            train_graph = graph.subgraph_within_dates(sg.min_date, sgs[i + 4].max_date)\n",
    "            train_graph.embeddings = prev.embeddings\n",
    "            train_graph.emb_cols = prev.emb_cols\n",
    "            train_pairs = prev.make_pairs_with_edges(train_graph, .5, enforce_non_edge=False, enforce_has_embeddings=True)\n",
    "            df_train, y_train = prev.to_dataframe(pairs=train_pairs, label_graph=train_graph)\n",
    "            rf = RandomForestClassifier(n_estimators=500, max_depth=None, min_samples_split=2, random_state=0, n_jobs=-1)\n",
    "            fields = prev.emb_cols\n",
    "            x_train = df_train.loc[:, fields]\n",
    "            classifier = rf.fit(x_train, y_train)\n",
    "            print(\"Model fitted\")\n",
    "        if i == 8:\n",
    "            test_graph = graph.subgraph_within_dates(sg.min_date, sgs[i+4].max_date)\n",
    "            test_graph.embeddings = prev.embeddings\n",
    "            test_graph.emb_cols = prev.emb_cols\n",
    "            test_pairs = prev.make_pairs_with_edges(test_graph, .5, enforce_non_edge=False, enforce_has_embeddings=True)\n",
    "            df_test, y_test = prev.to_dataframe(test_pairs, label_graph=test_graph)\n",
    "            fields = prev.emb_cols\n",
    "            x_test = df_test.loc[:, fields]\n",
    "            pred = classifier.predict_proba(x_test)\n",
    "            print(\"Prediction made.... Done\")\n",
    "            break\n",
    "        sg.generate_embeddings_with_prev(prev.embeddings, 128)\n",
    "        sg.save_betas(beta_file, degree_graph=cum)\n",
    "        sg.perform_walks(p=.5, q=.5)\n",
    "        sg.save_walks(walk_file)\n",
    "        process = subprocess.Popen(emb_command, stderr=subprocess.PIPE)\n",
    "        err = process.communicate()\n",
    "        if err[0]:\n",
    "            print(err)\n",
    "        sg.load_embeddings(embed_file)  # update embeddings with output from w2v\n",
    "        sg.save_embeddings(init_file, 128)\n",
    "        distance = core_movement(sg.embeddings)\n",
    "        prev_embeds = store_core_embeds(sg.embeddings)\n",
    "        print(\"Distance this iteration: %.4f\" % distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.958908360982\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print roc_auc_score(y_test, pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}